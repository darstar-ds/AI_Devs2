JeÅ›li film nie wyÅ›wietla siÄ™ poprawnie, tutaj [wersja YouTube](https://youtu.be/IGRB0tRINZY)

* * *

Ta lekcja bÄ™dzie nieco luÅºniejsza od pozostaÅ‚ych, poniewaÅ¼ jej celem jest zarysowanie **moÅ¼liwie szerokiego horyzontu** moÅ¼liwoÅ›ci duÅ¼ych modeli jÄ™zykowych. Znajdziesz w niej zatem "jedynie" opisy oraz rÃ³Å¼ne wskazÃ³wki dotyczÄ…ce pracy z modelami. **WdroÅ¼eniem wymienionych mechanik zajmiemy siÄ™ w dalszej czÄ™Å›ci kursu**.

Na tej podstawie Å‚atwiej bÄ™dzie Ci decydowaÄ‡, ktÃ³re mechaniki zastosowaÄ‡ w swojej pracy. Potraktuj wiÄ™c tÄ™ lekcjÄ™ jako sesjÄ™ inspiracji oraz sprÃ³buj przenieÅ›Ä‡ (i modyfikowaÄ‡) prezentowane przykÅ‚ady na swojÄ… codziennoÅ›Ä‡.

* * *

Rozumienie oraz generowanie treÅ›ci przez LLM otwiera przed nami rÃ³Å¼ne Å›cieÅ¼ki zastosowania AI w swojej codziennoÅ›ci, kontekÅ›cie zawodowym i biznesowym. Pomimo tego, gÅ‚Ã³wna komunikacja firm takich jak OpenAI, Microsoftu czy Google nierzadko opiera siÄ™ na prostych aktywnoÅ›ciach takich jak **podsumowania** i **rozwijania** dokumentÃ³w, czy maili. Z jednej strony rozumiem koniecznoÅ›Ä‡ prezentowania prostych przykÅ‚adÃ³w dla ogÃ³Å‚u spoÅ‚eczeÅ„stwa. Z drugiej, nie jest dla mnie jasne, dlaczego w sieci tak rzadko spotykam zastosowania wykraczajÄ…ce poza banalne przykÅ‚ady z ChatGPT.

Z drugiej strony, gdy bardziej zaawansowane zastosowania siÄ™ pojawiajÄ…, to zwykle obecny rozwÃ³j LLM nie pozwala ich wprost przenieÅ›Ä‡ na naszÄ… codziennoÅ›Ä‡. PrzykÅ‚adem moÅ¼e byÄ‡ [prezentacja OpenAI](https://youtu.be/outcGtbnMuQ?t=992) prezentujÄ…ca moÅ¼liwoÅ›Ä‡ przeniesienia szkicu strony Internetowej na funkcjonalny kod. I choÄ‡ pobudziÅ‚o to wyobraÅºniÄ™ oglÄ…dajÄ…cych (rÃ³wnieÅ¼ mojÄ…), to w praktyce nigdy w ten sposÃ³b nie uzyskaÅ‚em satysfakcjonujÄ…cego rezultatu. Nie zmienia to jednak faktu, Å¼e z modeli Vision korzystam praktycznie kaÅ¼dego dnia.

Zatem istnieje znaczna rÃ³Å¼nica pomiÄ™dzy komunikatami marketingowymi oraz ogÃ³lnymi rekomendacjami, ktÃ³re zwykle skierowane sÄ… do szerokiego grona odbiorcÃ³w, a codziennym zastosowaniem. Podobnie teÅ¼ istnieje przepaÅ›Ä‡ pomiÄ™dzy "prototypem" a produkcyjnym rozwiÄ…zaniem, czego moÅ¼emy doÅ›wiadczyÄ‡ na co dzieÅ„.

Aby skutecznie posÅ‚ugiwaÄ‡ siÄ™ LLM w kodzie czy automatyzacjach, konieczne jest wiÄ™c uchwycenie nie tylko skupionej na detalach perspektywy, lecz uchwycenia szerokiego obrazu moÅ¼liwoÅ›ci, ktÃ³re mamy do dyspozycji dziÅ› oraz ktÃ³re pojawiÄ… siÄ™ w przyszÅ‚oÅ›ci.

 
W "Å›wiecie AI" niemal codziennie pojawiajÄ… siÄ™ nowe narzÄ™dzia, techniki, publikacje naukowe, czy nawet modele. Takie otoczenie wymaga zmiany niektÃ³rych nawykÃ³w, a nierzadko dostosowania naszej rutyny zwiÄ…zanej z naukÄ…, programowaniem, czy tworzeniem produktÃ³w. DuÅ¼Ä… rÃ³Å¼nicÄ™ robi takÅ¼e samo **praktyczne zastosowanie AI** w swojej pracy, nawet jeÅ›li ograniczamy siÄ™ do stosunkowo prostych zadaÅ„. Jednak najwiÄ™kszy wpÅ‚yw na umiejÄ™tnoÅ›Ä‡ dostosowania siÄ™ do wysokiego tempa zmian, wydaje siÄ™ odgrywaÄ‡ **poÅ‚Ä…czenie wÅ‚asnego doÅ›wiadczenia, osÄ…du, rozumowania, etyki pracy oraz wiedzy na temat ograniczeÅ„ i moÅ¼liwoÅ›ci narzÄ™dzi AI**. MÃ³wiÄ…c konkretnie:

*   Czy GPT-4 samodzielnie wdroÅ¼y nowÄ… funkcjonalnoÅ›Ä‡ w moim produkcie? Nie.
    
*   Czy GPT-4 buduje fragmenty tych funkcjonalnoÅ›ci? Tak.
    
*   Czy GPT-4 napisze za mnie lekcjÄ™ AI Devs? Nie.
    
*   Czy GPT-4 pomaga mi w parafrazie i zwiÄ™kszeniu czytelnoÅ›ci? Tak.
    
*   Czy GPT-4 rozwiÄ…Å¼e kaÅ¼dy programistyczny problem? Nie.
    
*   Czy GPT-4 przyspiesza mi rozwiÄ…zywanie programistycznych problemÃ³w? Tak.
    
*   Czy GPT-4 potrafi rozumieÄ‡ szeroki kontekst moich projektÃ³w? Nie.
    
*   Czy GPT-4 potrafi mi eksplorowaÄ‡ wybrane obszary moich projektÃ³w i planowaÄ‡ zmiany? Tak.
    

GPT-4 samodzielnie osiÄ…ga przeciÄ™tne wyniki lub wprost nie jest w stanie wykonaÄ‡ wielu zadaÅ„. Sam nie jestem w stanie dziaÅ‚aÄ‡ tak szybko, jak GPT-4, jednak efekty mojej pracy sÄ… nieporÃ³wnywalnie lepsze niÅ¼ te, wygenerowane przez AI.

Wniosek jest prosty â€” najwiÄ™ksza korzyÅ›Ä‡ pÅ‚ynie z poÅ‚Ä…czenia naszego doÅ›wiadczenia i umiejÄ™tnoÅ›ci z LLM. Tylko na czym to poÅ‚Ä…czenie konkretnie polega?

*   Nie oczekujÄ™ od modelu, Å¼e rozwiÄ…Å¼e moje problemy. OczekujÄ™, Å¼e pomoÅ¼e mi dojÅ›Ä‡ do ich rozwiÄ…zania.
    
*   Nie oczekujÄ™ od modelu, Å¼e napisze za mnie caÅ‚Ä… logikÄ™ funkcjonalnoÅ›ci, nad ktÃ³rÄ… pracujÄ™. OczekujÄ™, Å¼e pomoÅ¼e mi w jej fragmentach.
    
*   Nie generujÄ™ kodu, ktÃ³rego nie jestem w stanie zrozumieÄ‡, bo wprowadzenie w nim zmian zajmie mi dÅ‚uÅ¼ej niÅ¼ zbudowanie wszystkiego od podstaw. W zamian poruszam siÄ™ **na granicy mojej aktualnej kompetencji** (czasem nieznacznie wychodzÄ…c poza niÄ…)
    
*   Nie dÄ…Å¼Ä™ do tego, aby AI zwolniÅ‚o mnie z robienia trudnych rzeczy. WykorzystujÄ™ AI po to, aby **daÅ‚o mi przestrzeÅ„ do ich realizacji**.
    
*   Nie opieram swojej nauki na pÅ‚ytkich podsumowaniach generowanych przez GPT-4. Korzystam z podsumowaÅ„ po to, aby w sposÃ³b **dopasowany do mnie** uÅ‚atwiÄ‡ sobie zrozumienie wybranych zagadnieÅ„.
    
*   Nie korzystam z AI, aby generowaÅ‚o za mnie publikowane treÅ›ci czy wiadomoÅ›ci. Korzystam z AI po to, aby pomagaÅ‚o mi kontrolowaÄ‡ merytorykÄ™ i jasnoÅ›Ä‡ przekazu wynikajÄ…cÄ… ze sposobu formuÅ‚owania myÅ›li.
    

Poza **poÅ‚Ä…czeniem z AI** oraz dbaniem o to, aby **korzystaÄ‡ z moÅ¼liwie najlepszych ÅºrÃ³deÅ‚ wiedzy (wymieniaÅ‚em je w lekcji C01L01), jakie jestem w stanie znaleÅºÄ‡ w Internecie**, poÅ›wiÄ™cam tak duÅ¼o uwagi, jak to moÅ¼liwe, na **samodzielne testowanie i eksplorowanie dostÄ™pnych moÅ¼liwoÅ›ci**. To, co wÅ‚aÅ›nie mam na myÅ›li, Å›wietnie oddaje fragment rozmowy Andreja Karpathy z Lexem Fridmanem. Podczas niej padÅ‚a sugestia dla osÃ³b poczÄ…tkujÄ…cych w obszarze Machine Learningu, jednak ma to zastosowanie do wszystkich innych dziedzin. Mianowicie "PoczÄ…tkujÄ…cy sÄ… zwykle skupieni na tym, 'co robiÄ‡', niÅ¼ na tym, aby 'robiÄ‡ duÅ¼o'". ([ÅºrÃ³dÅ‚o](https://www.youtube.com/watch?v=I2ZK3ngNvvI&t=15s)).

![](https://assets.circle.so/vvc3mi4kc4f75hjpg2x01p3zglcl)

BudujÄ…c integracje z LLM czy innymi narzÄ™dziami AI, nie zawsze skupiam siÄ™ na uÅ¼ytecznoÅ›ci mojego rozwiÄ…zania, lecz na szerokim i nierzadko bardzo gÅ‚Ä™bokim eksplorowaniu technologii. ChwilÄ™ pÃ³Åºniej okazuje siÄ™, Å¼e mechaniki, ktÃ³re zastosowaÅ‚em np. w powiadomieniach gÅ‚osowych, przydajÄ… mi siÄ™ przy pracy z transkrypcjami wideo, z ktÃ³rymi pracujÄ™, rozwijajÄ…c asystenta eduweb.

PrzykÅ‚adem prototypu, ktÃ³ry sam w sobie posÅ‚uÅ¼yÅ‚ mi tylko do sprawdzenia w praktyce pewnych zaÅ‚oÅ¼eÅ„, jest strumieniowanie tokenÃ³w z GPT-4 bezpoÅ›rednio do usÅ‚ugi text-to-speech (w tym przypadku ElevenLabs). PoniÅ¼ej widaÄ‡ fragment dÅ‚ugiej konwersacji, podczas ktÃ³rej z pomocÄ… Alice wprowadzaÅ‚em poprawki w mechanice tego prototypu.

ZwrÃ³Ä‡ uwagÄ™, Å¼e ze wzglÄ™du na dÅ‚ugi wÄ…tek, zadbaÅ‚em o podanie bieÅ¼Ä…cego kontekstu w postaci kodu, o ktÃ³rym mÃ³wiÄ™, aby zwiÄ™kszyÄ‡ prawdopodobieÅ„stwo tego, Å¼e uzyskam poprawnÄ… odpowiedÅº.

![](https://assets.circle.so/u4f3temqf7t4yenj5sy4w6o4o4jl)

Zasadniczo, podczas tworzenia **niezaleÅ¼nych prototypÃ³w** lub **elementÃ³w istniejÄ…cych aplikacji**, warto zawsze pamiÄ™taÄ‡ o tym, jak model interpretuje dane, ktÃ³re mu przekazujemy.

*   Zarysowanie kontekstu projektu oraz naszego poziomu doÅ›wiadczenia pozwala na zwiÄ™kszenie precyzji odpowiedzi.
    
*   Dostarczanie fragmentÃ³w dokumentacji lub informacji, ktÃ³re pozwalajÄ… zarysowaÄ‡ kontekst (a jednoczeÅ›nie nie sÄ… to informacje poufne), zmniejsza ryzyko halucynacji oraz zwiÄ™ksza jakoÅ›Ä‡ odpowiedzi.
    
*   Ograniczenie zakresu omawianego problemu pozwala na skupienie uwagi modelu tam, gdzie jest to w danej chwili potrzebne.
    
*   PosÅ‚ugiwanie siÄ™ krÃ³tkimi fragmentami kodu oraz ograniczanie generowania kodu przez model, uÅ‚atwia rozumienie, debugowanie i wprowadzanie zmian.
    
*   Restartowanie konwersacji takÅ¼e pozwala sterowaÄ‡ uwagÄ… modelu i zmieniaÄ‡ kierunek omawianego rozwiÄ…zania.
    
*   Zapisywanie historii wiadomoÅ›ci w swojej wÅ‚asnej bazie umoÅ¼liwia Å‚atwy powrÃ³t do wczeÅ›niejszych konwersacji, rÃ³wnieÅ¼ z pomocÄ… wyszukiwarki.
    

Naturalnie, Ty **nie musisz** dziaÅ‚aÄ‡ w ten sposÃ³b. Jednak niewykluczone, Å¼e w powyÅ¼szej wypowiedzi znajdziesz wÄ…tki, ktÃ³re z powodzeniem przeÅ‚oÅ¼ysz na swojÄ… codziennoÅ›Ä‡. Zasadniczo mÃ³wimy tutaj przede wszystkim **o faktycznym zastosowaniu GPT-4 w swojej pracy oraz Å‚Ä…czeniu swojego doÅ›wiadczenia z moÅ¼liwoÅ›ciami AI.**

 
Na poczÄ…tku powiedziaÅ‚em, Å¼e nie bÄ™dziemy omawiaÄ‡ technik projektowania promptÃ³w, ktÃ³rych opisy i przykÅ‚ady Å‚atwo znajdziesz w sieci. Musisz jednak wiedzieÄ‡, czego szukaÄ‡. Oto lista, ktÃ³ra Ci w tym pomoÅ¼e:

*   **Zero-shot Prompting** polega na zdolnoÅ›ci modelu do wykonania zadania na podstawie prostej instrukcji, ktÃ³ra nie zawiera przykÅ‚adÃ³w
    
*   **One-shot / Few-shot Prompting** polega na podawaniu przykÅ‚adÃ³w prezentujÄ…cych oczekiwane zachowanie modelu. OmÃ³wiliÅ›my to powyÅ¼ej.
    
*   **Chain of Thought** polega na prowadzeniu modelu przez ciÄ…g myÅ›lowy z pomocÄ… wiedzy dostarczonej przez nas lub wygenerowanej przez model. PrzykÅ‚adowo szukajÄ…c odpowiedzi na nasze pytanie, moÅ¼emy opisaÄ‡Â sytuacjÄ™ w ktÃ³rej siÄ™ znajdujemy oraz kroki, ktÃ³re juÅ¼Â podjÄ™liÅ›my.
    
*   **Zero-shot Chain of Thought** polega uÅ¼yciu wyraÅ¼enia "think step by step" w ktÃ³rego wyniku model **wyjaÅ›ni swoje rozumowanie** przechodzÄ…c przez kolejne kroki, ktÃ³re **zwiÄ™kszajÄ… prawdopodobieÅ„stwo wygenerowania poprawnej odpowiedzi**
    
*   **Reflexion** polega na uÅ¼yciu wyraÅ¼enia np. "let's verify this step by step" w celu **zweryfikowania odpowiedzi wygenerowanej przez model**. Zasadniczo chodzi o to, aby model **samodzielnie** znalazÅ‚Â ewentualne bÅ‚Ä™dy w swoim rozumowaniu lub potwierdziÅ‚Â swojÄ… dotychczasowÄ…Â odpowiedÅº
    
*   **Tree of Thoughts** polega na **wygenerowaniu moÅ¼liwych scenariuszy**, **pogÅ‚Ä™bieniu ich**, **wybraniu najbardziej prawdopodobnych** i **udzieleniu odpowiedzi**. Åatwo zauwaÅ¼yÄ‡, Å¼e wÃ³wczas generowanie odpowiedzi trwa dÅ‚uÅ¼ej, jednak wedÅ‚ug [tej publikacji](https://arxiv.org/abs/2305.10601) dla pewnego zestawu zadaÅ„, skutecznoÅ›Ä‡ modelu wzrosÅ‚a z 4% (Chain of Thought) do 74%!
    
*   Bonus: **SmartGPT** to technika rozwijana przez twÃ³rcÄ™ kanaÅ‚u [https://www.youtube.com/@aiexplained-official](https://www.youtube.com/@aiexplained-official), ktÃ³ra jest Å›wietnym przykÅ‚adem tego, Å¼e moÅ¼na w kreatywny sposÃ³b podchodziÄ‡ nie tylko do projektowania promptÃ³w, ale takÅ¼e **ich Å‚Ä…czenia**.
    

WiÄ™cej na temat technik projektowania promptÃ³w, znajdziesz tutaj: [https://www.promptingguide.ai](https://www.promptingguide.ai/). W AI\_Devs skupimy siÄ™Â na praktycznym wykorzystaniu tych technik w poÅ‚Ä…czeniu z kodem oraz wejdziemy nieco gÅ‚Ä™biej w obszar Prompt Engineeringu. Nie musisz przechodziÄ‡ przez wszystkie zagadnienia wymienione na wspomnianej stronie, ale moÅ¼esz z niej korzystaÄ‡.

 
Wiedza na temat modeli oraz ogÃ³lnych zasad projektowania promptÃ³w nie jest wystarczajÄ…ca do tego, aby robiÄ‡ to skutecznie. OczywiÅ›cie zakÅ‚adajÄ…c, Å¼e chcemy projektowaÄ‡ coÅ› wiÄ™cej, niÅ¼ proste interakcje. Powodem tego jest fakt, Å¼e pracujemy tutaj z jÄ™zykiem naturalnym, a to wymaga dodatkowej kreatywnoÅ›ci, szerokiej wiedzy, bogatego sÅ‚ownictwa i ogÃ³lnej precyzji. **Nawet jeÅ›li swobodnie czujesz siÄ™Â w tych obszarach**, to niezwykle pomocna przy projektowaniu promptÃ³w staje siÄ™ sztuczna inteligencja, a konkretnie GPT-4 dostÄ™pny w Playground.

ProjektujÄ…c prompt w ten sposÃ³b, pamiÄ™taj o tym, aby:

*   Instrukcja systemowa nadawaÅ‚a odpowiedniÄ… rolÄ™, np. Senior Prompt Engineer oraz przedstawiaÅ‚a cel rozmowy
    
*   Zacznij od prostego promptu, aby nadaÄ‡ ogÃ³lny ton, ktÃ³ry rozbudujesz wspÃ³lnie z GPT-4
    
*   W instrukcji musisz uwzglÄ™dniÄ‡ takÅ¼e wyraÅºne podkreÅ›lenie tego, aby model **nie realizowaÅ‚ instrukcji w podanym przez uÅ¼ytkownika prompcie**
    
*   Warto takÅ¼e zasugerowaÄ‡, aby pierwsza interakcja umoÅ¼liwiaÅ‚a przekazanie promptu przez uÅ¼ytkownika, a odpowiedÅº modelu zawieraÅ‚a jedynie jego przeglÄ…d i wstÄ™pne rekomendacje, ktÃ³re pozwolÄ… Ci zaczÄ…Ä‡, **bez ich natychmiastowego wprowadzania**
    
*   OczywiÅ›cie model nie posiada zdolnoÅ›ci do perfekcyjnej analizy Twoich promptÃ³w, ale trafnie wskazuje rÃ³Å¼nego rodzaju bÅ‚Ä™dy logiki czy sugeruje zmiany sÅ‚Ã³w, czy wyraÅ¼eÅ„
    
*   Przy projektowaniu promptÃ³w korzystaj z GPT-4-Turbo lub Claude 3 Opus (gdy bÄ™dziesz mieÄ‡ dostÄ™p).
    
*   Natomiast sterowanie projektowaniem promptu pozostawiaj sobie i podejmuj wszystkie decyzje zwiÄ…zane z jego modyfikowaniem
    

PrzykÅ‚ad Playground, ktÃ³ry ja wykorzystujÄ™ do swojej pracy, znajdziesz poniÅ¼ej. **Nie jest to jednak instrukcja z ktÃ³rej korzystam zawsze**, lecz raczej schemat, wokÃ³Å‚ ktÃ³rego siÄ™ poruszam. SzczegÃ³Å‚y zawsze rÃ³Å¼niÄ… siÄ™Â w zaleÅ¼noÅ›ci od tego, jaki prompt chcÄ™ zaprojektowaÄ‡.

![](https://assets.circle.so/wp0fm74p4edd7m0pcbm06l6mpy5y)

â€” ğŸ”— [zobacz przykÅ‚ad](https://platform.openai.com/playground/p/Cx1IqImlXBnW5LORydujRUKY?model=gpt-4&mode=chat)

DokÅ‚adnie na tej samej zasadzie moÅ¼esz pracowaÄ‡ nie tylko nad promptami, ale takÅ¼e innymi zadaniami wymagajÄ…cymi precyzji oraz moÅ¼liwoÅ›ci **duÅ¼ej kontroli nad zachowaniem modelu**. Playground jest Å›wietnym narzÄ™dziem, ktÃ³re sprawdza siÄ™ w takich sytuacjach. PamiÄ™taj o moÅ¼liwoÅ›ci zapisywania interakcji przyciskiem "Save" oraz **dbaj o czytelne i zrozumiaÅ‚e nazwy zapisanych interakcji**.

Proces projektowania promptÃ³w wyglÄ…da wiÄ™c zatem u mnie nastÄ™pujÄ…co:

*   **Szkic:** Pierwszy, ogÃ³lny szkic, majÄ…cy na celu rozpoznanie zachowania modelu dla konkretnego zadania. Na tym etapie pomijam kwestiÄ™ optymalizacji i skupiam siÄ™Â na dojÅ›ciu do celu.
    
*   **Weryfikacja:** Drugi etap polega na przygotowaniu zestawÃ³w danych weryfikujÄ…cych zarÃ³wno najbardziej prawdopodobne zastosowania, jak i te, niemal absurdalne, ktÃ³re przyjdÄ… mi do gÅ‚owy, majÄ…ce na celu caÅ‚kowicie zaburzyÄ‡ dziaÅ‚anie promptu. UwzglÄ™dniam tutaj takÅ¼e **zachowanie promptu dla wiÄ™kszych zestawÃ³w danych**, np. obszernego kontekstu lub dÅ‚uÅ¼szej konwersacji
    
*   **Uruchomienie:** Trzeci etap zaleÅ¼y od przeznaczenia promptu. ZakÅ‚adajÄ…c, Å¼e mÃ³wimy o przetwarzaniu dokumentÃ³w, to podÅ‚Ä…czam kilka **krÃ³tszych** plikÃ³w i sprawdzam, jak wyglÄ…dajÄ…Â efekty. Na tym etapie zwykle od razu wprowadzam jakieÅ› poprawki.
    
*   **Brainstorm:** WspÃ³lnie z GPT-4, korzystajÄ…c z Playground przeprowadzam analizÄ™ na podstawie moich obserwacji, sugestii modelu oraz moich przemyÅ›leÅ„. Gdy widzÄ™, Å¼e GPT-4 rozumie dziaÅ‚anie mojego promptu, przechodzimy do wykrycia nieÅ›cisÅ‚oÅ›ci czy zastosowania lepszych wyraÅ¼eÅ„. Na tym etapie nierzadko dochodzi takÅ¼e do **optymalizacji** pod kÄ…tem dÅ‚ugoÅ›ci promptu. Podczas tego etapu nierzadko podÄ…Å¼am za sugestiami GPT-4, natomiast i tak **ostateczna decyzja pozostaje po mojej stronie**
    
*   **Iteracja:** Wracam do punktu drugiego i kontynuujÄ™ proces do osiÄ…gniÄ™cia poÅ¼Ä…danych rezultatÃ³w oraz poczucia, Å¼e "moja praca jest tutaj zrobiona". Nierzadko w kolejnych iteracjach przeÅ‚Ä…czam prompt na sÅ‚absze, ale szybsze modele w wersji 3.5 i jeÅ›li to moÅ¼liwe, pozostajÄ™ przy nich w celu optymalizacji kosztÃ³w.
    

OczywiÅ›cie moÅ¼esz opracowaÄ‡ swÃ³j wÅ‚asny proces. Sam nie stosujÄ™ jeszcze testÃ³w automatycznych moich promptÃ³w, aczkolwiek zdarza mi siÄ™ wykonywaÄ‡ proste skrypty przechodzÄ…ce przez zestaw danych testowych. JeÅ›li rezultatem dziaÅ‚ania jest wynik, ktÃ³ry mogÄ™ zweryfikowaÄ‡ programistycznie (np. wygenerowanym przez GPT-4 wyraÅ¼eniem regularnym), to oczywiÅ›cie to robiÄ™.

* * *

 
W lekcji **C01L03** wskazaÅ‚em popularne techniki promptÃ³w oraz ÅºrÃ³dÅ‚a, w ktÃ³rych moÅ¼esz znaleÅºÄ‡ ich wiÄ™cej. Miej jednak na uwadze, Å¼e nieustannie powstajÄ… sposoby interakcji z modelami, jak chociaÅ¼by ostatnia publikacja "[Large Language Models are Optimizers](https://arxiv.org/abs/2309.03409)", mÃ³wiÄ…ca o moÅ¼liwoÅ›ci wykorzystywania LLM do optymalizacji swoich wÅ‚asnych zachowaÅ„.

Z programistycznego (lub no-code) punktu widzenia, generowanie odpowiedzi na podstawie **procesu realizowanego przez kilka zapytaÅ„** moÅ¼e odbywaÄ‡ siÄ™ automatycznie, a uÅ¼ytkownicy takiego systemu, mogÄ… widzieÄ‡ jedynie ostatecznÄ… odpowiedÅº.

PoniÅ¼ej znajduje siÄ™ przykÅ‚ad kodu ([**08\_cot**](https://github.com/i-am-alice/2nd-devs/tree/main/08_cot)) prezentujÄ…cego **natychmiastowe zwrÃ³cenie odpowiedzi przez model** (zero-shot) oraz **staranne wyjaÅ›nienie swojego rozumowania (zero-shot chain of thought)**. W tym drugim przypadku **model miaÅ‚ wiÄ™cej czasu do "namysÅ‚u"**, po ktÃ³rym miaÅ‚ **doÅ‚Ä…czyÄ‡ separator, a nastÄ™pnie podaÄ‡ wynik w formie liczby**. DziÄ™ki unikatowemu separatorowi mogÅ‚em programistycznie pobraÄ‡ rezultat i wykorzystaÄ‡ go w dalszym fragmencie aplikacji.

![](https://assets.circle.so/doc2kx9qn9sozfjuajx0q5hmn44i)

Na kilkanaÅ›cie prÃ³b, **zero-shot CoT** **generowaÅ‚ poprawny wynik za kaÅ¼dym razem** (model GPT-4), podczas gdy zero-shot **myliÅ‚ siÄ™ za kaÅ¼dym razem!** Analogicznie, moÅ¼esz tutaj skorzystaÄ‡ z Chain of Thought, Tree of Thought, czy Reflexion. OczywiÅ›cie, DuÅ¼e Modele JÄ™zykowe nie sÄ… przeznaczone do dokonywania obliczeÅ„, jednak mÃ³wimy tutaj o ogÃ³lnym zwiÄ™kszeniu zdolnoÅ›ci do logicznego myÅ›lenia i starannym generowaniu odpowiedzi.

Tutaj widaÄ‡, Å¼e uzasadnione staje siÄ™ zastosowanie guardrails, dziÄ™ki ktÃ³rym mÃ³gÅ‚bym siÄ™ upewniÄ‡, Å¼e faktycznie otrzymam oczekiwanÄ… przeze mnie odpowiedÅº w postaci liczby. Nie bÄ™dziemy tego teraz robiÄ‡, ale zwracam uwagÄ™ na to, **w jaki sposÃ³b te wszystkie koncepcje siÄ™Â ze sobÄ… Å‚Ä…czÄ….**

